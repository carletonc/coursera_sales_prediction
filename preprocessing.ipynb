{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856ba06-5c97-468f-a3cb-bd7148578fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876a6be-8ad9-4eee-921d-40fdd0b07e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('tmp/data/raw/sample_submission.csv').set_index('ID')\n",
    "print(sample_submission.shape)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd21a1-93a3-48b7-b6e4-b45099d23da4",
   "metadata": {},
   "source": [
    "## Process Test\n",
    "\n",
    "Let's start with our test set and work backwords so we don't engineer features unreleated to it.\n",
    "\n",
    "To maintain the integrity of the output we need to generate from the test set, set we need to predict on, we replace the duplicate shop IDs rather than dropping them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4bbc1d-a618-401b-b616-a610924d8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('tmp/data/raw/test.csv').set_index('ID')\n",
    "test.loc[test['shop_id'] == 0, 'shop_id'] = 57  # Якутск Орджоникидзе, 56\n",
    "test.loc[test['shop_id'] == 1, 'shop_id'] = 58  # Якутск ТЦ \"Центральный\"\n",
    "test.loc[test['shop_id'] == 10, 'shop_id'] = 11  # Жуковский ул. Чкалова 39м²\n",
    "test.to_pickle('tmp/data/processed/test.pkl')\n",
    "print(test.shape)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e18ef3-2589-4ac6-a7b1-4147b818b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some global variables for future gleaning\n",
    "unique_test_shops = test['shop_id'].unique().tolist()\n",
    "unique_test_items = test['item_id'].unique().tolist()\n",
    "print(f'Unique shops:\\t{len(unique_test_shops)}')\n",
    "print(f'Unique items:\\t{len(unique_test_items)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc2731-beed-4e97-a5bc-3b11c8857469",
   "metadata": {},
   "source": [
    "## Process Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc6495c-8d6c-4969-a5e5-e4f1989e36ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop('item_name', axis=1)\n",
    "items = pd.read_csv('tmp/data/raw/items.csv')\n",
    "print(items.shape)\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571805c-f2a3-403e-9b79-f4da2707dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop items we won't predict on\n",
    "# we could tokenize the item_names for similarity, but we won't in order to minimize complexity\n",
    "items = items.loc[items['item_id'].isin(unique_test_items)].reset_index(drop=True)\n",
    "print(items.shape)\n",
    "items.to_pickle('tmp/data/processed/items.pkl')\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6262ddb-bbad-444c-9989-d5b737e37883",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_test_categories = items['item_category_id'].unique().tolist()\n",
    "print(f'Unique categories:\\t{len(unique_test_categories)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfb1401-6009-4005-a77b-bb77c2d297c1",
   "metadata": {},
   "source": [
    "## Process Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d587323a-f095-4661-98ac-67192db6c27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = pd.read_csv('tmp/data/raw/item_categories.csv')\n",
    "print(cats.shape)\n",
    "cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6331426-165f-4a90-b8eb-8f71e65d3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop items we won't predict on\n",
    "cats = cats.loc[cats['item_category_id'].isin(unique_test_categories)].reset_index(drop=True)\n",
    "print(cats.shape)\n",
    "cats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ac27a-6656-4454-bdc2-b25d9db3d1ba",
   "metadata": {},
   "source": [
    "Honestly, I manually googled the Russian text, and saw that the categories had inconsisent naming conventions. Rather than writing explicit rules to clean the text, I decided to try a naive approach by tokenizing the categories and 1-hot encoding them. This way, a category that had `PC` at the start or end of a category would still get the `PC` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5d176-12db-4715-900c-d5e2b8eebdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories could be general enough for help indicate popularity/sales, so we translate them to features.\n",
    "cats['split'] = cats['item_category_name'].apply(lambda x: x.split('-'))\n",
    "#cats['cat'] = cats['split'].apply(lambda x: x[0].strip())\n",
    "#cats['subcat'] = cats['split'].apply(lambda x: x[1].strip() if len(x) > 1 else np.NaN)\n",
    "cats['split'] = cats['item_category_name'].apply(lambda x: x.replace('- ', ' ').replace(':', ' ').split())\n",
    "cats['split'] = cats['split'].apply(lambda x: [i.strip().lstrip('(').rstrip(')').strip() for i in x])\n",
    "\n",
    "binarizer = MultiLabelBinarizer().fit(cats['split'])\n",
    "cat_classes = [f'cat_{c}' for c in binarizer.classes_]\n",
    "cats[cat_classes] = binarizer.transform(cats['split'])\n",
    "cats = cats.drop(['item_category_name', 'split'], axis=1)\n",
    "feats = cats[cats.columns[1:]].sum().reset_index().sort_values(0)\n",
    "feats = ['item_category_id'] + feats.loc[feats[0]>1, 'index'].tolist()\n",
    "cats = cats[feats]\n",
    "\n",
    "cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a6776-1def-4dd4-8212-cae5698d6d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.drop('item_name', axis=1)\n",
    "cats = items.merge(cats, on='item_category_id', how='left')\n",
    "cats = cats.drop('item_category_id', axis=1)\n",
    "cats.to_pickle('tmp/data/processed/categories.pkl')\n",
    "print(cats.shape)\n",
    "cats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6672c1-7cff-4bb0-857a-6684499a0c74",
   "metadata": {},
   "source": [
    "## Process Shops\n",
    "\n",
    "Filter for the shops only in the test set, which inherently drops the mislabeled shops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb627c-b397-418a-999d-3b6bcbd1a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shops = pd.read_csv('tmp/data/raw/shops.csv')\n",
    "shops = shops.loc[shops['shop_id'].isin(unique_test_shops)]\n",
    "print(shops.shape)\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c49ae-b30b-4f7c-8ba6-0c7bcefcdfc5",
   "metadata": {},
   "source": [
    "Candidly, I googled a lot of the Russian words to discover the shop names contain cities, shop types, and addresses, so we create binarized features cities and shop types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93bb8e-788d-45b5-84b4-ccf1da91c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# City features\n",
    "\n",
    "# Выездная Торговля = offsite trade\n",
    "# Интернет-магазин ЧС = emergency online store\n",
    "# Цифровой склад 1С-Онлайн = digital warehouse 1-c online\n",
    "other = list(['Выездная Торговля', 'Интернет-магазин ЧС', 'Цифровой склад 1С-Онлайн'])\n",
    "\n",
    "shops['city'] = np.NaN\n",
    "shops.loc[~shops['shop_name'].isin(other), 'city'] = shops.loc[~shops['shop_name'].isin(other), 'shop_name'].apply(lambda x: x.split(' ')[0])\n",
    "shops.loc[shops['city']=='Сергиев', 'city'] = 'Сергиев Посад'\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d327c59e-ec10-4327-a384-382f9dea3e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shop Type features\n",
    "traveling = 'Выездная Торговля'\n",
    "online = list(['Интернет-магазин ЧС', 'Цифровой склад 1С-Онлайн'])\n",
    "\n",
    "shops['shop_type'] = np.NaN # np.NaN\n",
    "shop_type = ['ТЦ', 'ТРК', 'ТРЦ', 'МТРЦ', 'ТК']\n",
    "for st in shop_type:\n",
    "    shops.loc[shops['shop_name'].str.contains(st), 'shop_type'] = st\n",
    "\n",
    "shops.loc[shops['shop_name'].isin(online), 'shop_type'] = 'Online'\n",
    "shops.loc[shops['shop_name']==traveling, 'shop_type'] = 'Traveling'\n",
    "\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642eeba3-83dd-465a-b009-eddc915b4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address was considered as a feature, but we will avoid it to reduce complexity\n",
    "shops['address'] = np.NaN # np.NaN\n",
    "for i in shops.index:\n",
    "    shop_name = shops.loc[i, 'shop_name']\n",
    "    city = shops.loc[i, 'city']\n",
    "    shop_type = shops.loc[i, 'shop_type']\n",
    "    \n",
    "    address = shop_name\n",
    "    for n in (other + list([city]) + list([shop_type])):\n",
    "        if isinstance(n, str):\n",
    "            address = address.lstrip(n).strip()\n",
    "    shops.loc[i, 'address'] = address\n",
    "    \n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb6801-059e-40b1-b920-59ae1e192546",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "binarizer = LabelBinarizer().fit(shops['city'].fillna('None'))\n",
    "city_classes = [f'city_{c}' for c in [c.replace(' ', '_') for c in binarizer.classes_]]\n",
    "shops[city_classes] = binarizer.transform(shops['city'].fillna('None'))\n",
    "\n",
    "binarizer = LabelBinarizer().fit(shops['shop_type'].fillna('None'))\n",
    "shop_type_classes = [f'shop_type_{c}' for c in [c.replace(' ', '_') for c in binarizer.classes_]]\n",
    "shops[shop_type_classes] = binarizer.transform(shops['shop_type'].fillna('None'))\n",
    "    \n",
    "shops = shops.drop(['shop_name', 'address', 'city', 'city_None', 'shop_type', 'shop_type_None'], axis=1)\n",
    "shops = shops.fillna(0)\n",
    "shops.to_pickle('tmp/data/processed/shops.pkl')\n",
    "print(shops.shape)\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d222819-aaf7-4069-aac0-212f9d13b71e",
   "metadata": {},
   "source": [
    "## Process Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f59865c-3e95-4372-a0d0-33c14b62b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('tmp/data/raw/sales_train.csv')\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f26c2ff-7bca-43d5-819d-5d2ec5ce2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.loc[train['shop_id'].isin(unique_test_shops) & train['item_id'].isin(unique_test_items)]\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4ed5a5-9d20-406d-a52e-5ad4f69ddae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates\n",
    "train['date'] = pd.to_datetime(train['date'], format=\"%d.%m.%Y\")\n",
    "train['month'] = train['date'].dt.month\n",
    "train['year'] = train['date'].dt.year\n",
    "train.drop(['date'], axis=1, inplace=True)\n",
    "\n",
    "train['revenue'] = train['item_price'] * train['item_cnt_day']\n",
    "\n",
    "train = train.groupby(['date_block_num', 'month', 'year', 'shop_id', 'item_id']).agg({'revenue':'sum', 'item_cnt_day':'sum'}).reset_index()\n",
    "train = train.rename(columns={'item_cnt_day':'item_cnt_month'})\n",
    "\n",
    "# Kaggle competition states output is capped at 20, so we clip our outputs to predict on\n",
    "train['item_cnt_month'] = train['item_cnt_month'].clip(0, 20)\n",
    "\n",
    "print(train.shape)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231449f-0a4f-4ca2-a54b-4e8450923405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the dataframe with timestamps and zero sale months\n",
    "cols = ['date_block_num', 'month', 'year', 'shop_id', 'item_id']\n",
    "dates = train.copy().groupby(['date_block_num', 'month', 'year']).sum().reset_index()[['date_block_num', 'month', 'year']]\n",
    "\n",
    "train_mod = list()\n",
    "for dtup in dates.itertuples():\n",
    "    for shop_id in unique_test_shops:\n",
    "        for item_id in unique_test_items:\n",
    "            vals = list([dtup[1], dtup[2], dtup[3], shop_id, item_id])\n",
    "            train_mod.append(vals)\n",
    "            \n",
    "train_mod = pd.DataFrame(train_mod, columns=cols)\n",
    "\n",
    "# merge expanded dataset\n",
    "train = train_mod.merge(train, on=cols, how='left').fillna(0)\n",
    "del train_mod\n",
    "train.to_pickle('tmp/data/processed/train.pkl')\n",
    "print(train.shape)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d04d4e1-bd01-4a4c-8388-fec4c4e29ca2",
   "metadata": {},
   "source": [
    "## Revisit the test set to add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb04748a-e69d-4a38-9422-f3b294f29b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('tmp/data/processed/test.pkl')\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd0e4c-3f5c-4288-ac42-defd25dfc14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['date_block_num']==33].groupby(['date_block_num', 'month', 'year']).count().reset_index()[['date_block_num', 'month', 'year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f720510-ae13-41c9-a421-5a453d14a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['date_block_num'] = 34\n",
    "test['month'] = 11\n",
    "test['year'] = 2015\n",
    "test['revenue'] = 0\n",
    "test['item_cnt_month'] = 0\n",
    "test = test[['date_block_num', 'month', 'year', 'shop_id', 'item_id', 'revenue', 'item_cnt_month']]\n",
    "test.to_pickle('tmp/data/processed/test_plus_features.pkl')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f167ccee-7f9e-49a3-b583-7be7090ed891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
